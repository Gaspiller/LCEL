{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18fd2b2e-b096-4051-ba83-9197844da772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76428d60-e534-4fc5-bd96-e576089a6b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6676a50c-9e17-4a2c-bf91-1d189ed6da56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'loader.md'}, page_content='# 我是一个markdown加载示例\\n- 第一项目\\n- 第二个项目\\n- 第三个项目\\n\\n## 第一个项目\\nAI研习社最厉害专业的AI研究基地\\n\\n## 第二个项目\\nAIGC打造未来AI应用天地\\n\\n## 第三个项目\\nAI研习社是一个非常牛逼的AI媒体')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "loader = TextLoader(\"loader.md\", encoding=\"utf-8\")\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab3849cf-826b-43d0-986c-0352c127ef11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'loader.csv', 'row': 0}, page_content='\\ufeffProject: AI GC培训\\nDES: 培训课程\\nPrice: 500\\nPeople: 100\\nLocation: 北京'), Document(metadata={'source': 'loader.csv', 'row': 1}, page_content='\\ufeffProject: AI工程师认证\\nDES: 微软AI认证\\nPrice: 6000\\nPeople: 200\\nLocation: 西安'), Document(metadata={'source': 'loader.csv', 'row': 2}, page_content='\\ufeffProject: AI应用大会\\nDES: AI应用创新大会\\nPrice: 200门票\\nPeople: 300\\nLocation: 深圳'), Document(metadata={'source': 'loader.csv', 'row': 3}, page_content='\\ufeffProject: AI 应用咨询服务\\nDES: AI与场景结合\\nPrice: 1000/小时\\nPeople: 50\\nLocation: 香港'), Document(metadata={'source': 'loader.csv', 'row': 4}, page_content='\\ufeffProject: AI项目可研\\nDES: 可行性报告\\nPrice: 20000\\nPeople: 60\\nLocation: 上海')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(file_path=\"loader.csv\", encoding=\"utf-8\")\n",
    "data = loader.load()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e30ce81-45a1-43b1-bb63-577ecdea38e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'loader.html', 'title': 'RAG:将检索与生成方式相结合来做生成任务 - 知乎'}, page_content='RAG:将检索与生成方式相结合来做生成任务 - 知乎首发于自然语言处理算法与实践切换模式写文章登录/注册RAG:将检索与生成方式相结合来做生成任务烛之文\\u200ba worker in NLP1、前言在上一篇<kNN-NER：利用knn近邻算法来做命名实体识别>提及到文中提出kNN-NER框架是一种检索式增强的方法（retrieval augmented methods），就去查看有关retrieval augmented的paper，了解其核心思想，觉得检索式增强的方法很适合许多业务场景使用，因其以一种简捷的方式将外部知识融于模型中去。今天就分享一篇来自Facebook AI Research的paper<Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks>，论文提出一种检索式增强生成方法，应用于知识密集型的NLP任务（如问答生成），该篇论文被2020年NeurIPS 会议接收。文中说到，以BERT之类的大规模预训练模型将很多事实知识信息存入模型中，可以看着是pre-trained parametric类型，尽管以fine-tuned方式在下游任务取得显著的成效，但这类方法仍存在无法精准地获取和操作知识的缺陷。而在上述提及的问题上，传统知识检索的方法能很好的应对，这类方法可以看着是non-parametric memory类型。于是，论文提出检索式增强生成方法（retrieval-augmented generation，RAG），主要思想就是将pre-trained parametric与non-parametric memory结合起来做语言生成任务，将两类模型集成起来提高任务处理效果。2、RAG方法上图为论文提出RAG模型的整体示意图。主要包括两大模块：一个检索器（Retriever， p_\\\\eta(z|x) ） + 一个生成器（Generator， p_\\\\theta(y_i|x,z,y_{1:i-1}) ）。前者包括query encoder和document index，分别负责query的编码和文档的索引；后者是一个seq2seq的生成模型。在检索中，使用的是最大内积搜索的方法（MIPS）来检索top-K相关文档。最后，把检索器输出的信息当成额外的文本信息，通过边际化的方式（marginalize）融于生成器中，生成最终的序列。在融合过程中，论文提出两种不同的方式：RAG-Sequence Model和RAG-Token Model，主要区别在于前者利用同一篇文档来生成所有序列；后者是用检索到的所有文档来生成序列。其计算方式如下：关于检索器 p_\\\\eta(z|x) ，由输入query x经过encoder得到编码向量q(x)，另外将知识库里的文档事先通过编码器得到文档编码向量d(z)，然后q(x)与d(z)做最大内积搜索到top-K相关文档，输出作为 p_\\\\eta(z|x) 。关于生成器 p_\\\\theta(y_i|x,z,y_{1:i-1}) ，论文中是用BART-large作为训练模型，然后将query x和检索到的z输入其中得到生成的序列文本。在解码过程中，RAG-Token Model可视为一个标准的自回归生成模型，按常规的beam search方式就可以解码；而在RAG-Sequence Model中，因为每个文档都生成一个序列，不能正常的beam search方式来解码。文中是对每个文档按beam search解码出一个序列，得到解码序列集合，针对每个生成序列，用其生成概率与 p_\\\\eta(z|x) 点乘得到一个概率score，取最大值对应的序列为最终输出。3、实验论文在四类Knowledge-Intensive 任务上进行实验，具体包括开放问答（Open-domain Question Answering ）、摘要式问答（Abstractive Question Answering） 、开放问题生成（Jeopardy Question Generation）、事实判断（Fact Verification ），并使用维基百科（包含2100万个文档）作为检索库。上表显示：在Open-domain Question Answering 任务上，论文提出的两个方法在4个数据集都取得新的最佳结果。上表显示，在Jeopardy Question Generation任务（Jeopardy数据集）上，RAG-Tok取得最优结果，且RAG都超过BART的表现；在Abstractive Question Answering任务（MSMARCO数据集）上，RAG模型都优于BART模型，但接近已有的最佳模型，其原因是论文在实验中没有利用数据集中包含文档 gold access信息；在Fact Verification任务上（FVR3,FVR2数据集） 上，对于3-way分类（FVR3），RAG比最优模型差4.3%，然而这类最优模型都是基于复杂的pipeline方法，需要大量的中间特征工程，而RAG不需要这些特征工程就可以达到接近的效果。此外，论文显示对比BART，RAG模型生成的文本更符合事实，更准确，且多样化。4、结语本次分享基于检索增强方式将外部知识融于生成任务中一个新的框架——RAG。对比T5 和 BART这类擅长处理生成任务的模型来说，RAG更新外部知识是不需要重新预训练，成本低；而对比pipeline方法，RAG利用外部知识并不需要构造负责的特征工程。总的来说，RAG方法可作为外部知识融合框架的一种有效实例。有兴趣可关注笔者公众号：自然语言处理算法与实践编辑于 2022-04-06 10:47深度学习（Deep Learning）机器学习检索数据库\\u200b赞同 16\\u200b\\u200b添加评论\\u200b分享\\u200b喜欢\\u200b收藏\\u200b申请转载\\u200b文章被以下专栏收录自然语言处理算法与实践')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import BSHTMLLoader\n",
    "loader = BSHTMLLoader(\"loader.html\", open_encoding=\"utf-8\")\n",
    "data = loader.load()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37079ef5-4fb1-4095-9b99-e8ff2570ae21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
