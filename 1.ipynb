{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e59d9fd-3a33-4318-9884-68d10f77e8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78d4ff6b-5a91-4ec6-a80a-f38db33338b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "afa0d045-811e-4f58-91e2-25bf780988f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a language model AI created by OpenAI known as GPT-3. My purpose is to assist and provide information to users based on the prompts given to me. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"yourself\"}\n",
    "]\n",
    "\n",
    "res = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    stream=False,\n",
    ")\n",
    "\n",
    "print(res.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55fce284-039b-48d9-ab7f-2ee3892daa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b003d53a-3c54-49e6-b19b-c1dfca0cbf52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\25746\\AppData\\Local\\Temp\\ipykernel_15144\\3244529240.py:1: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI(\n",
      "C:\\Users\\25746\\AppData\\Local\\Temp\\ipykernel_15144\\3244529240.py:6: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  llm.predict(\"introduce youself\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nHello! My name is [Name] and I am [age] years old. I am from [hometown/country] and I currently live in [current city]. I am a [occupation/study] and I am passionate about [interest/hobby]. In my free time, I enjoy [activity/hobby]. I am excited to get to know you all and be a part of this community!'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI(\n",
    "    model = \"gpt-3.5-turbo-instruct\",\n",
    "    temperature = 0,\n",
    "    openai_api_key = api_key,\n",
    ")\n",
    "llm.predict(\"introduce youself\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e96dd3f2-d512-497b-b9c8-908295565d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='你是一个起名大师. 你的名字叫陈大师.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='你好陈大师,你感觉如何？', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='你好！我状态非常好!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='你叫什么名字呢?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='你好！我叫陈大师', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='你的爸爸是谁呢?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你是一个起名大师. 你的名字叫{name}.\"),\n",
    "        (\"human\", \"你好{name},你感觉如何？\"),\n",
    "        (\"ai\", \"你好！我状态非常好!\"),\n",
    "        (\"human\", \"你叫什么名字呢?\"),\n",
    "        (\"ai\", \"你好！我叫{name}\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_template.format_messages(name=\"陈大师\", user_input=\"你的爸爸是谁呢?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7ce6ea0-42d3-4a57-b643-1109f3ff9048",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import StringPromptTemplate\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f04a196-fe55-4a14-becf-623f2ca40db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "函数名称: hello_world\n",
      "源代码:\n",
      "def hello_world(abc):\n",
      "    print(\"Hello, world!\")\n",
      "    return abc\n",
      "\n",
      "代码解释:\n",
      "这是一个名为hello_world的函数，它接受一个参数abc，并打印出\"Hello, world!\"，最后返回参数abc。它的作用是打印出\"Hello, world!\"这句话，并将参数abc返回。\n"
     ]
    }
   ],
   "source": [
    "def hello_world(abc):\n",
    "    print(\"Hello, world!\")\n",
    "    return abc\n",
    "\n",
    "PROMPT = \"\"\"\\\n",
    "你是一个非常有经验和天赋的程序员，现在给你如下函数名称，你会按照如下格式，输出这段代码的名称、源代码、中文解释。\n",
    "函数名称: {function_name}\n",
    "源代码:\n",
    "{source_code}\n",
    "代码解释:\n",
    "\"\"\"\n",
    "\n",
    "def get_source_code(function_name):\n",
    "    return inspect.getsource(function_name)\n",
    "\n",
    "class CustmPrompt(StringPromptTemplate):\n",
    "    def format(self, **kwargs) -> str:\n",
    "        source_code = get_source_code(kwargs[\"function_name\"])\n",
    "        return PROMPT.format(\n",
    "            function_name=kwargs[\"function_name\"].__name__,\n",
    "            source_code=source_code\n",
    "        )\n",
    "\n",
    "a = CustmPrompt(input_variables=[\"function_name\"])\n",
    "pm = a.format(function_name=hello_world)\n",
    "\n",
    "msg = llm.predict(pm)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e924173-d024-4ffc-885c-6396bfaa9adc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
